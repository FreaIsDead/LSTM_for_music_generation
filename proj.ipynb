{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"proj.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1vwxP15eTr6OO_AhTzsEALyJaRDmkCPJI","authorship_tag":"ABX9TyMQ5fguQBVr2BSoHk2wzQ1c"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"_-MjpC427iH4"},"source":["#training musica classica"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaPPA3dTaIIk"},"source":["\"\"\" This file permits to create the Data set from midi files and train_setup the neural network \"\"\"\r\n","import glob\r\n","import pickle\r\n","import numpy\r\n","from music21 import converter, instrument, note, chord\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.layers import Dropout\r\n","from keras.layers import LSTM\r\n","from keras.layers import Activation\r\n","from keras.layers import BatchNormalization as BatchNorm\r\n","from keras.utils import np_utils\r\n","from keras.callbacks import ModelCheckpoint\r\n","from tensorflow.keras.utils import plot_model\r\n","\r\n","\r\n","def main():\r\n","    # use this to transform midi files into encoded list of notes/chords\r\n","    #notes = get_notes()\r\n","\r\n","    #  use this to load encoded notes/chords list from a pickle file\r\n","    notes = []\r\n","    # this path must be changed!\r\n","    with (open(\"/content/drive/MyDrive/Università/Anno4/Natural Interaction/data/jazz\", \"rb\")) as openfile:\r\n","        notes = pickle.load(openfile)\r\n","\r\n","    # this is the length of unique notes/chords (number of elements in out Vocabulary Domain)\r\n","    n_elems = len(set(notes))\r\n","\r\n","    network_input, network_output = sequences_generator(notes, n_elems)\r\n","\r\n","    model = build_network(network_input, n_elems)\r\n","\r\n","    train_setup(model, network_input, network_output)\r\n","\r\n","\r\n","def get_notes():\r\n","    \"\"\" Get all the notes and chords from the midi files \"\"\"\r\n","    notes = []\r\n","\r\n","    # this path must be changed!\r\n","    for file in glob.glob(\"/content/*.mid\"):\r\n","        midi = converter.parse(file)\r\n","        notes_to_parse = None\r\n","        try:  # file has instrument parts\r\n","            s2 = instrument.partitionByInstrument(midi)\r\n","            notes_to_parse = s2.parts[0].recurse()\r\n","        except:  # file has notes in a flat structure\r\n","            notes_to_parse = midi.flat.notes\r\n","\r\n","        for element in notes_to_parse:\r\n","            if isinstance(element, note.Note):\r\n","                notes.append(str(element.pitch))\r\n","            elif isinstance(element, chord.Chord):\r\n","                notes.append('.'.join(str(n) for n in element.normalOrder))\r\n","    # this path  must be changed!\r\n","    with open('/content/drive/MyDrive/Università/Anno4/Natural Interaction/data/jazz', 'wb') as filepath:\r\n","        pickle.dump(notes, filepath)\r\n","\r\n","    return notes\r\n","\r\n","\r\n","def sequences_generator(notes, n_elems):\r\n","    \"\"\" Prepare the sequences used by the neural network\"\"\"\r\n","    sequence_length = 100\r\n","\r\n","    # get all unique notes/chords\r\n","    elem_collection = sorted(set(item for item in notes))\r\n","\r\n","    # create a dictionary to map elements to integers\r\n","    note_to_int = dict((note, number)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    network_input = []\r\n","    network_output = []\r\n","\r\n","    # create input sequences and the corresponding outputs\r\n","    for i in range(0, len(notes) - sequence_length, 1):\r\n","        sequence_in = notes[i:i + sequence_length]\r\n","        sequence_out = notes[i + sequence_length]\r\n","        network_input.append([note_to_int[char] for char in sequence_in])\r\n","        network_output.append(note_to_int[sequence_out])\r\n","\r\n","    n_patterns = len(network_input)\r\n","\r\n","    # reshape the input into a format compatible with LSTM layers\r\n","    network_input = numpy.reshape(\r\n","        network_input, (n_patterns, sequence_length, 1))\r\n","    # normalize input\r\n","    network_input = network_input / float(n_elems)\r\n","    # one-hot encoding of the outputs\r\n","    network_output = np_utils.to_categorical(network_output)\r\n","\r\n","    return (network_input, network_output)\r\n","\r\n","\r\n","def build_network(network_input, n_elems):\r\n","    model = Sequential()\r\n","    model.add(LSTM(\r\n","        512,\r\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n","        recurrent_dropout=0.3,\r\n","        return_sequences=True\r\n","    ))\r\n","    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\r\n","    model.add(LSTM(512))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(256))\r\n","    model.add(Activation('relu'))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(n_elems))\r\n","    model.add(Activation('softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n","    #plot_model(model, to_file='lstm.png',\r\n","    #           show_shapes=True, show_layer_names=True)\r\n","    model.summary()\r\n","    return model\r\n","\r\n","\r\n","def train_setup(model, network_input, network_output):\r\n","    \"\"\" train the neural network with SGD \"\"\"\r\n","    # this paths must be changed!\r\n","    dir = \"/content/drive/MyDrive/Università/Anno4/Natural Interaction/ckp/\"\r\n","    filepath = dir+\"checkpoint-{epoch:02d}-{loss:.4f}.hdf5\"\r\n","    checkpoint = ModelCheckpoint(\r\n","        filepath,\r\n","        monitor='loss',\r\n","        verbose=0,\r\n","        save_best_only=True,\r\n","        mode='min'\r\n","    )\r\n","    callbacks_list = [checkpoint]\r\n","\r\n","    model.fit(network_input, network_output, epochs=1,\r\n","              batch_size=128, callbacks=callbacks_list)\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFFg7NRrbVtz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3DCDu7efnjX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LB9q5LFfcde7"},"source":["### generazione musica classica"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEUlpx1AcfyJ"},"source":["\"\"\"This file generates notes/chords and save them as midi file\"\"\"\r\n","import pickle\r\n","import numpy\r\n","from music21 import instrument, note, stream, chord\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.layers import Dropout\r\n","from keras.layers import LSTM\r\n","from keras.layers import BatchNormalization as BatchNorm\r\n","from keras.layers import Activation\r\n","\r\n","\r\n","def main():\r\n","    # this path must be changed!\r\n","    # first I load the notes-pickle file that will be used to choose a random sequence for starting generation of new elements\r\n","    with open('/content/drive/MyDrive/Università/Anno4/Natural Interaction/data/classic', 'rb') as filepath:\r\n","        notes = pickle.load(filepath)\r\n","\r\n","    # get all unique notes/chords\r\n","    elem_collection = sorted(set(item for item in notes))\r\n","    # this is the length of unique notes/chords (number of elements in out Vocabulary Domain)\r\n","    n_elems = len(set(notes))\r\n","\r\n","    network_input, normalized_input = sequences_generator(\r\n","        notes, elem_collection, n_elems)\r\n","    model = build_network(normalized_input, n_elems)\r\n","    for i in range(5):\r\n","      s = \"out{}.mid\".format(i)\r\n","      prediction_output = generate_notes(\r\n","          model, network_input, elem_collection, n_elems)\r\n","      create_midi(prediction_output,s)\r\n","\r\n","\r\n","def sequences_generator(notes, elem_collection, n_elems):\r\n","    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\r\n","    # map between notes and integers and back\r\n","    note_to_int = dict((note, number)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    sequence_length = 100\r\n","    network_input = []\r\n","    output = []\r\n","    for i in range(0, len(notes) - sequence_length, 1):\r\n","        sequence_in = notes[i:i + sequence_length]\r\n","        sequence_out = notes[i + sequence_length]\r\n","        network_input.append([note_to_int[char] for char in sequence_in])\r\n","        output.append(note_to_int[sequence_out])\r\n","\r\n","    n_patterns = len(network_input)\r\n","\r\n","    # reshape the input into a format compatible with LSTM layers\r\n","    normalized_input = numpy.reshape(\r\n","        network_input, (n_patterns, sequence_length, 1))\r\n","    # normalize input\r\n","    normalized_input = normalized_input / float(n_elems)\r\n","\r\n","    return (network_input, normalized_input)\r\n","\r\n","\r\n","def build_network(network_input, n_elems):\r\n","    \"\"\" create the structure of the neural network \"\"\"\r\n","    model = Sequential()\r\n","    model.add(LSTM(\r\n","        512,\r\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n","        recurrent_dropout=0.3,\r\n","        return_sequences=True\r\n","    ))\r\n","    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\r\n","    model.add(LSTM(512))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(256))\r\n","    model.add(Activation('relu'))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(n_elems))\r\n","    model.add(Activation('softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n","\r\n","    # Load the weights to each node\r\n","    dir = \"/content/drive/MyDrive/Università/Anno4/Natural Interaction/ckp/\"\r\n","    model.load_weights(dir+'classic.hdf5')\r\n","\r\n","    return model\r\n","\r\n","\r\n","def generate_notes(model, network_input, elem_collection, n_elems):\r\n","    \"\"\" Generate notes from the neural network based on an initial sequence of notes \"\"\"\r\n","    # first we take a random sequence from the input as a starting point for the generation\r\n","    numpy.random.seed(int(time.time()))\r\n","    start = numpy.random.randint(0, len(network_input)-1)\r\n","\r\n","    int_to_note = dict((number, note)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    pattern = network_input[start]\r\n","    prediction_output = []\r\n","\r\n","    # generate 'n' notes\r\n","    for _ in range(150):\r\n","        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\r\n","        prediction_input = prediction_input / float(n_elems)\r\n","\r\n","        prediction = model.predict(prediction_input, verbose=0)\r\n","\r\n","        index = numpy.argmax(prediction)\r\n","        result = int_to_note[index]\r\n","        prediction_output.append(result)\r\n","\r\n","        pattern.append(index)\r\n","        pattern = pattern[1:len(pattern)]\r\n","\r\n","    return prediction_output\r\n","\r\n","\r\n","def create_midi(prediction_output, name):\r\n","    \"\"\" Convert the predictions output to notes and then create a midi file \"\"\"\r\n","    offset = 0\r\n","    output_notes = []\r\n","\r\n","    # create note and chord objects based on the values generated by the model\r\n","    for elem in prediction_output:\r\n","        # elem is a chord\r\n","        if ('.' in elem) or elem.isdigit():\r\n","            notes_in_chord = elem.split('.')\r\n","            notes = []\r\n","            for current_note in notes_in_chord:\r\n","                new_note = note.Note(int(current_note))\r\n","                new_note.storedInstrument = instrument.Piano()\r\n","                notes.append(new_note)\r\n","            new_chord = chord.Chord(notes)\r\n","            new_chord.offset = offset\r\n","            output_notes.append(new_chord)\r\n","        # elem is a note\r\n","        else:\r\n","            new_note = note.Note(elem)\r\n","            new_note.offset = offset\r\n","            new_note.storedInstrument = instrument.Piano()\r\n","            output_notes.append(new_note)\r\n","\r\n","        # increase offset each iteration so that notes do not stack\r\n","        # offset refers to where the note is located in the piece.\r\n","        offset += 0.5\r\n","\r\n","    midi_stream = stream.Stream(output_notes)\r\n","\r\n","    midi_stream.write('midi', fp=name)\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_ZzhhtvxJzl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRv09e1gxJxn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LW9zs1o3xJvO"},"source":["#training jazz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GBrFtAo7mOJ"},"source":["\"\"\" This file permits to create the Data set from midi files and train_setup the neural network \"\"\"\r\n","import glob\r\n","import pickle\r\n","import numpy\r\n","from music21 import converter, instrument, note, chord\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense\r\n","from tensorflow.keras.layers import Dropout\r\n","from tensorflow.keras.layers import LSTM\r\n","from tensorflow.keras.layers import Activation\r\n","from tensorflow.keras.layers import BatchNormalization as BatchNorm\r\n","from tensorflow.keras.callbacks import ModelCheckpoint\r\n","from tensorflow.keras.utils import to_categorical\r\n","from tensorflow.keras.utils import plot_model\r\n","\r\n","\r\n","def main():\r\n","    # use this to transform midi files into encoded list of notes/chords\r\n","    #notes = get_notes()\r\n","\r\n","    #  use this to load encoded notes/chords list from a pickle file\r\n","    notes = []\r\n","    # this path must be changed!\r\n","    with (open(\"data/jazz\", \"rb\")) as openfile:\r\n","        notes = pickle.load(openfile)\r\n","    notes = notes[:int(len(notes)/5)]\r\n","\r\n","    # this is the length of unique notes/chords (number of elements in out Vocabulary Domain)\r\n","    n_elems = len(set(notes))\r\n","\r\n","    network_input, network_output = sequences_generator(notes, n_elems)\r\n","\r\n","    model = build_network(network_input, n_elems)\r\n","\r\n","    train_setup(model, network_input, network_output)\r\n","\r\n","\r\n","def get_notes():\r\n","    \"\"\" Get all the notes and chords from the midi files \"\"\"\r\n","    notes = []\r\n","\r\n","    # this path must be changed!\r\n","    for file in glob.glob(\"midi/*.mid\"):\r\n","        midi = converter.parse(file)\r\n","        notes_to_parse = None\r\n","        try:  # file has instrument parts\r\n","            s2 = instrument.partitionByInstrument(midi)\r\n","            notes_to_parse = s2.parts[0].recurse()\r\n","        except:  # file has notes in a flat structure\r\n","            notes_to_parse = midi.flat.notes\r\n","\r\n","        for element in notes_to_parse:\r\n","            if isinstance(element, note.Note):\r\n","                notes.append(str(element.pitch))\r\n","            elif isinstance(element, chord.Chord):\r\n","                notes.append('.'.join(str(n) for n in element.normalOrder))\r\n","    # this path  must be changed!\r\n","    with open('data/jazz', 'wb') as filepath:\r\n","        pickle.dump(notes, filepath)\r\n","\r\n","    return notes\r\n","\r\n","\r\n","def sequences_generator(notes, n_elems):\r\n","    \"\"\" Prepare the sequences used by the neural network\"\"\"\r\n","    sequence_length = 80\r\n","\r\n","    # get all unique notes/chords\r\n","    elem_collection = sorted(set(item for item in notes))\r\n","\r\n","    # create a dictionary to map elements to integers\r\n","    note_to_int = dict((note, number)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    network_input = []\r\n","    network_output = []\r\n","\r\n","    # create input sequences and the corresponding outputs\r\n","    for i in range(0, len(notes) - sequence_length, 1):\r\n","        sequence_in = notes[i:i + sequence_length]\r\n","        sequence_out = notes[i + sequence_length]\r\n","        network_input.append([note_to_int[char] for char in sequence_in])\r\n","        network_output.append(note_to_int[sequence_out])\r\n","\r\n","    n_patterns = len(network_input)\r\n","\r\n","    # reshape the input into a format compatible with LSTM layers\r\n","    network_input = numpy.reshape(\r\n","        network_input, (n_patterns, sequence_length, 1))\r\n","    # normalize input\r\n","    network_input = network_input / float(n_elems)\r\n","    # one-hot encoding of the outputs\r\n","    network_output = to_categorical(network_output)\r\n","\r\n","    return (network_input, network_output)\r\n","\r\n","\r\n","def build_network(network_input, n_elems):\r\n","    model = Sequential()\r\n","    model.add(LSTM(\r\n","        704,\r\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n","        recurrent_dropout=0.3,\r\n","        return_sequences=True\r\n","    ))\r\n","    model.add(LSTM(704, return_sequences=True, recurrent_dropout=0.3,))\r\n","    model.add(LSTM(704))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(640))\r\n","    model.add(Activation('relu'))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(n_elems))\r\n","    model.add(Activation('softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n","    # plot_model(model, to_file='lstm.png',\r\n","    #           show_shapes=True, show_layer_names=True)\r\n","    model.summary()\r\n","    return model\r\n","\r\n","\r\n","def train_setup(model, network_input, network_output):\r\n","    \"\"\" train the neural network with SGD \"\"\"\r\n","    # this paths must be changed!\r\n","    dir = \"ckp/\"\r\n","    filepath = dir+\"checkpoint-{epoch:02d}-{loss:.4f}.hdf5\"\r\n","    checkpoint = ModelCheckpoint(\r\n","        filepath,\r\n","        monitor='loss',\r\n","        verbose=0,\r\n","        save_best_only=True,\r\n","        mode='min'\r\n","    )\r\n","    callbacks_list = [checkpoint]\r\n","\r\n","    model.fit(network_input, network_output, epochs=1000,\r\n","              batch_size=128, callbacks=callbacks_list)\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwtKnOXo7mL-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvahVQLb7mJq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUevPTmExJnG"},"source":["#generazione jazz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFzl9HDRxNB8"},"source":["\"\"\"This file generates notes/chords and save them as midi file\"\"\"\r\n","import pickle\r\n","import numpy\r\n","import time\r\n","from music21 import instrument, note, stream, chord\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.layers import Dropout\r\n","from keras.layers import LSTM\r\n","from keras.layers import BatchNormalization as BatchNorm\r\n","from keras.layers import Activation\r\n","\r\n","\r\n","def main():\r\n","    # this path must be changed!\r\n","    # first I load the notes-pickle file that will be used to choose a random sequence for starting generation of new elements\r\n","    with open('/content/drive/MyDrive/Università/Anno4/Natural Interaction/data/jazz', 'rb') as filepath:\r\n","        notes = pickle.load(filepath)\r\n","    notes = notes[:int(len(notes)/5)]\r\n","\r\n","    # get all unique notes/chords\r\n","    elem_collection = sorted(set(item for item in notes))\r\n","    # this is the length of unique notes/chords (number of elements in out Vocabulary Domain)\r\n","    n_elems = len(set(notes))\r\n","\r\n","    network_input, normalized_input = sequences_generator(\r\n","        notes, elem_collection, n_elems)\r\n","    model = build_network(normalized_input, n_elems)\r\n","    for i in range(5):\r\n","      s = \"out{}.mid\".format(i)\r\n","      prediction_output = generate_notes(\r\n","          model, network_input, elem_collection, n_elems)\r\n","      create_midi(prediction_output,s)\r\n","\r\n","\r\n","def sequences_generator(notes, elem_collection, n_elems):\r\n","    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\r\n","    # map between notes and integers and back\r\n","    note_to_int = dict((note, number)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    sequence_length = 80\r\n","    network_input = []\r\n","    output = []\r\n","    for i in range(0, len(notes) - sequence_length, 1):\r\n","        sequence_in = notes[i:i + sequence_length]\r\n","        sequence_out = notes[i + sequence_length]\r\n","        network_input.append([note_to_int[char] for char in sequence_in])\r\n","        output.append(note_to_int[sequence_out])\r\n","\r\n","    n_patterns = len(network_input)\r\n","\r\n","    # reshape the input into a format compatible with LSTM layers\r\n","    normalized_input = numpy.reshape(\r\n","        network_input, (n_patterns, sequence_length, 1))\r\n","    # normalize input\r\n","    normalized_input = normalized_input / float(n_elems)\r\n","\r\n","    return (network_input, normalized_input)\r\n","\r\n","\r\n","def build_network(network_input, n_elems):\r\n","    \"\"\" create the structure of the neural network \"\"\"\r\n","    model = Sequential()\r\n","    model.add(LSTM(\r\n","        704,\r\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n","        recurrent_dropout=0.3,\r\n","        return_sequences=True\r\n","    ))\r\n","    model.add(LSTM(704, return_sequences=True, recurrent_dropout=0.3,))\r\n","    model.add(LSTM(704))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(640))\r\n","    model.add(Activation('relu'))\r\n","    model.add(BatchNorm())\r\n","    model.add(Dropout(0.3))\r\n","    model.add(Dense(n_elems))\r\n","    model.add(Activation('softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n","\r\n","    # Load the weights to each node\r\n","    dir = \"/content/drive/MyDrive/Università/Anno4/Natural Interaction/ckp/\"\r\n","    model.load_weights(dir+'jazz.hdf5')\r\n","\r\n","    return model\r\n","\r\n","\r\n","def generate_notes(model, network_input, elem_collection, n_elems):\r\n","    \"\"\" Generate notes from the neural network based on an initial sequence of notes \"\"\"\r\n","    # first we take a random sequence from the input as a starting point for the generation\r\n","    numpy.random.seed(int(time.time()))\r\n","    start = numpy.random.randint(0, len(network_input)-1)\r\n","\r\n","    int_to_note = dict((number, note)\r\n","                       for number, note in enumerate(elem_collection))\r\n","\r\n","    pattern = network_input[start]\r\n","    prediction_output = []\r\n","\r\n","    # generate 'n' notes\r\n","    for _ in range(150):\r\n","        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\r\n","        prediction_input = prediction_input / float(n_elems)\r\n","\r\n","        prediction = model.predict(prediction_input, verbose=0)\r\n","\r\n","        index = numpy.argmax(prediction)\r\n","        result = int_to_note[index]\r\n","        prediction_output.append(result)\r\n","\r\n","        pattern.append(index)\r\n","        pattern = pattern[1:len(pattern)]\r\n","\r\n","    return prediction_output\r\n","\r\n","\r\n","def create_midi(prediction_output, name):\r\n","    \"\"\" Convert the predictions output to notes and then create a midi file \"\"\"\r\n","    offset = 0\r\n","    output_notes = []\r\n","\r\n","    # create note and chord objects based on the values generated by the model\r\n","    for elem in prediction_output:\r\n","        # elem is a chord\r\n","        if ('.' in elem) or elem.isdigit():\r\n","            notes_in_chord = elem.split('.')\r\n","            notes = []\r\n","            for current_note in notes_in_chord:\r\n","                new_note = note.Note(int(current_note))\r\n","                new_note.storedInstrument = instrument.Piano()\r\n","                notes.append(new_note)\r\n","            new_chord = chord.Chord(notes)\r\n","            new_chord.offset = offset\r\n","            output_notes.append(new_chord)\r\n","        # elem is a note\r\n","        else:\r\n","            new_note = note.Note(elem)\r\n","            new_note.offset = offset\r\n","            new_note.storedInstrument = instrument.Piano()\r\n","            output_notes.append(new_note)\r\n","\r\n","        # increase offset each iteration so that notes do not stack\r\n","        # offset refers to where the note is located in the piece.\r\n","        offset += 0.5\r\n","\r\n","    midi_stream = stream.Stream(output_notes)\r\n","\r\n","    midi_stream.write('midi', fp=name)\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPqJk_6Z7z4n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTsdjkHEymkE"},"source":["!apt install fluidsynth\r\n","!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8vTP5ig70LS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lkp43kuU5onC","executionInfo":{"status":"ok","timestamp":1611825555954,"user_tz":-60,"elapsed":2,"user":{"displayName":"edo morty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLRgkkIdTWN6QBQZHzu28-L5CypSQbH1s34QKY6Q=s64","userId":"04921946247635700796"}}},"source":["!fluidsynth -ni font.sf2 out0.mid -F out0.wav -r 44100\r\n","!fluidsynth -ni font.sf2 out1.mid -F out1.wav -r 44100\r\n","!fluidsynth -ni font.sf2 out2.mid -F out2.wav -r 44100\r\n","!fluidsynth -ni font.sf2 out3.mid -F out3.wav -r 44100\r\n","!fluidsynth -ni font.sf2 out4.mid -F out4.wav -r 44100"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEhcok8O0g9E"},"source":["from IPython.display import Audio \r\n","Audio('out0.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQRrz1tP0zRL"},"source":["from IPython.display import Audio \r\n","Audio('out1.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cy1S9Bts0zro"},"source":["from IPython.display import Audio \r\n","Audio('out2.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7a4uITf0z_r"},"source":["from IPython.display import Audio \r\n","Audio('out3.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvOK2N7e015B"},"source":["from IPython.display import Audio \r\n","Audio('out4.wav')"],"execution_count":null,"outputs":[]}]}